{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexledd/So-VITS-SVC-Notebook/blob/main/so-vits-svc_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Lq1uk_WfhG"
      },
      "source": [
        "## Before training\n",
        "\n",
        "This program saves the last 3 generations of models to Google Drive. Since 1 generation of models is >1GB, you should have at least 3GB of free space in Google Drive. If you do not have such free space, it is recommended to create another Google Account.\n",
        "\n",
        "Training requires >10GB VRAM. (T4 should be enough) Inference does not require such a lot of VRAM.\n",
        "\n",
        "**Notes: be cautius with your file/folder name, preferably without spaces!**\n",
        "\n",
        "**Also that playing audio directly in Colab can cause runtime to restart. To solve this, download it manually or move it inside /content/drive/MyDrive and play it over GDrive instead**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Zzk_dGQIXiiU"
      },
      "outputs": [],
      "source": [
        "#@title NVIDIA SMI (GPU Check)\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dan5obwKROnZ"
      },
      "source": [
        "# Dependencies & Mount Gdrive\n",
        "Restart runtime after everything is installed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "t_bTO4YJ13Pv"
      },
      "outputs": [],
      "source": [
        "#@title Mount GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ak4zlbFI4OBL"
      },
      "outputs": [],
      "source": [
        "#@title Audio editor dependencies\n",
        "\n",
        "!pip install yt_dlp\n",
        "!pip install ffmpeg\n",
        "!mkdir youtubeaudio\n",
        "!python3 -m pip install -U demucs\n",
        "!python3 -m pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_7o1i5jtN98h"
      },
      "outputs": [],
      "source": [
        "#@title SVC dependencies\n",
        "\n",
        "!python -m pip install -U pip wheel\n",
        "%pip install -U ipython\n",
        "%pip install -U so-vits-svc-fork\n",
        "!mkdir drive/MyDrive/so-vits-svc-fork\n",
        "#@markdown pip may fail to resolve dependencies and raise ERROR, but it can be ignored.\n",
        "#@markdown You need to restart the runtime after running this cell! (MUST!)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4Zlj0fa-RNd"
      },
      "source": [
        "# Downloader\n",
        "This cell is for downloading from the internet; url must be direct to the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7Be8zOQpUAVY"
      },
      "outputs": [],
      "source": [
        "#@title Downloader\n",
        "#@markdown The default downloads folder is in \"/content/downloaded\"\n",
        "file_url = \"https://huggingface.co/lexmill/alex-id_en/resolve/main/Alex_3200.pth\" #@param {type:\"string\"}\n",
        "file_url2 = \"https://huggingface.co/lexmill/alex-id_en/raw/main/config.json\" #@param {type:\"string\"}\n",
        "\n",
        "!mkdir downloaded\n",
        "!wget -N {file_url} -P downloaded/\n",
        "!wget -N {file_url2} -P downloaded/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iQG8AqbqPa3c"
      },
      "outputs": [],
      "source": [
        "#@title YouTube Audio Downloader (WAV Output)\n",
        "from __future__ import unicode_literals\n",
        "import yt_dlp\n",
        "import ffmpeg\n",
        "import sys\n",
        "\n",
        "ydl_opts = {\n",
        "    'format': 'bestaudio/best',\n",
        "#    'outtmpl': 'output.%(ext)s',\n",
        "    'postprocessors': [{\n",
        "        'key': 'FFmpegExtractAudio',\n",
        "        'preferredcodec': 'wav',\n",
        "    }],\n",
        "    \"outtmpl\": 'youtubeaudio/audio',  # this is where you can edit how you'd like the filenames to be formatted\n",
        "}\n",
        "def download_from_url(url):\n",
        "    ydl.download([url])\n",
        "    # stream = ffmpeg.input('output.m4a')\n",
        "    # stream = ffmpeg.output(stream, 'output.wav')\n",
        "\n",
        "\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "      url = \"\" #@param {type:\"string\"}\n",
        "      download_from_url(url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "G7IPEzmQEp0e"
      },
      "outputs": [],
      "source": [
        "#@title Unzip Tool\n",
        "ZIP_PATH = \"\" #@param {type:\"string\"}\n",
        "FOLDER_NAME = \"\" #@param {type:\"string\"}\n",
        "\n",
        "!unzip {ZIP_PATH} -d {FOLDER_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH_-DIk1RgTL"
      },
      "source": [
        "# Audio Editor\n",
        "This set is for audio editing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Z_UroiCWUqGD"
      },
      "outputs": [],
      "source": [
        "#@title Convert to Waveform (.WAV)\n",
        "#@markdown remove the file extension (.mp3;m4a) in input section. default output is in \"/content/converted\"\n",
        "FFMPEG_INPUT = \"\" #@param {type:\"string\"}\n",
        "FILE_EXT = \"\" #@param {type:\"string\"}\n",
        "OUT = \"\" #@param {type:\"string\"}\n",
        "\n",
        "!mkdir converted\n",
        "!ffmpeg -i {FFMPEG_INPUT}.{FILE_EXT} -acodec pcm_s16le /content/converted/{OUT}.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3_H8nINjQAEn"
      },
      "outputs": [],
      "source": [
        "#@title Demuxer (Seperate Vocal and Background)\n",
        "import subprocess\n",
        "AUDIO_INPUT = \"\" #@param {type:\"string\"}\n",
        "\n",
        "command = f\"demucs --two-stems=vocals {AUDIO_INPUT}\"\n",
        "result = subprocess.run(command.split(), stdout=subprocess.PIPE)\n",
        "print(result.stdout.decode())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-MVhrL0tE4yp"
      },
      "outputs": [],
      "source": [
        "#@title Analyzing Audio Volume\n",
        "ANLZ_INPUT = \"\" #@param {type:\"string\"}\n",
        "\n",
        "!ffmpeg -i {ANLZ_INPUT} -filter:a volumedetect -f null /dev/null!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TuQCJbLwFYeZ"
      },
      "outputs": [],
      "source": [
        "#@title Volume Manipulation\n",
        "VM_INPUT = \"\" #@param {type:\"string\"}\n",
        "#@markdown Value can be in \"1.5\" (150% Increase) or in \"10dB\" (10dB Increase)\n",
        "VM_VALUE = \"\" #@param {type:\"string\"}\n",
        "#@markdown Output filename; In /content/volume_changed\n",
        "VM_OUTPUT = \"\" #@param {type:\"string\"}\n",
        "\n",
        "!mkdir volume_changed\n",
        "!ffmpeg -i {VM_INPUT} -filter:a \"volume={VM_VALUE}\" -c:a pcm_s16le /content/volume_changed/{VM_OUTPUT}.volume.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_AL_8MBPA7RK"
      },
      "outputs": [],
      "source": [
        "#@title Audio Normalization\n",
        "#@markdown * Audio Normalization input; this cell will also convert audio file to waveform.\n",
        "AN_INPUT = \"\" #@param {type:\"string\"}\n",
        "#@markdown * Target loudness; type just the value in dB (ex. \"-6\")\n",
        "TARGET_LDNS = \"-6\" #@param {type:\"string\"}\n",
        "#@markdown * The default Loudness Range is 11dB\n",
        "RANGE_LDNS = \"11\" #@param {type:\"string\"}\n",
        "#@markdown * The default value is -1.5dB\n",
        "TRUE_PEAK = \"-1.5\" #@param {type:\"string\"}\n",
        "#@markdown * Output filename; in /content/normalized\n",
        "AN_OUTPUT = \"\" #@param {type:\"string\"}\n",
        "\n",
        "!mkdir normalized\n",
        "!ffmpeg -i {AN_INPUT} -af loudnorm=I={TARGET_LDNS}:LRA={RANGE_LDNS}:TP={TRUE_PEAK} -c:a pcm_s16le /content/normalized/{AN_OUTPUT}.normalized.wav\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9BhLtRDiT1-r"
      },
      "outputs": [],
      "source": [
        "#@title Combine\n",
        "from pydub import AudioSegment\n",
        "!mkdir combined\n",
        "\n",
        "AUDIO_01 = \"\" #@param {type:\"string\"}\n",
        "AUDIO_02 = \"\" #@param {type:\"string\"}\n",
        "DisplayAudio_Combined = False #@param {type:\"boolean\"}\n",
        "\n",
        "sound1 = AudioSegment.from_file(AUDIO_01)\n",
        "sound2 = AudioSegment.from_file(AUDIO_02)\n",
        "\n",
        "combined = sound1.overlay(sound2)\n",
        "\n",
        "combined.export(\"/content/combined/audio.combined.wav\", format='wav')\n",
        "\n",
        "def DisplayAudioResult():\n",
        "    display(Audio(f\"/content/combined/audio.combined.wav\"))\n",
        "\n",
        "if DisplayAudio_Combined :\n",
        "  DisplayAudioResult()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlMZYZIbRKdk"
      },
      "source": [
        "# Training\n",
        "This set is for training an SVC model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZHT28lsARvxP"
      },
      "outputs": [],
      "source": [
        "#@title Make dataset directory\n",
        "!mkdir -p \"dataset_raw\"\n",
        "\n",
        "#!rm -r \"dataset_raw\"\n",
        "#!rm -r \"dataset/44k\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JqIVEHklR6fu"
      },
      "outputs": [],
      "source": [
        "#@title Copy your dataset\n",
        "#@markdown **We assume that your dataset is in your Google Drive's `so-vits-svc-fork/dataset/(speaker_name)` directory.**\n",
        "DATASET_NAME = \"\" #@param {type: \"string\"}\n",
        "!cp -R /content/drive/MyDrive/so-vits-svc-fork/dataset/{DATASET_NAME}/ -t \"dataset_raw/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IOkrKJoHR_lv"
      },
      "outputs": [],
      "source": [
        "#@title Automatic preprocessing\n",
        "!svc pre-resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VmNJL40gSBGl"
      },
      "outputs": [],
      "source": [
        "#@title Pre-Config for new dataset\n",
        "!svc pre-config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1G0s7Cr_SB2k"
      },
      "outputs": [],
      "source": [
        "#@title Copy configs file\n",
        "!cp configs/44k/config.json drive/MyDrive/so-vits-svc-fork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8oqToxChST9j"
      },
      "outputs": [],
      "source": [
        "#@title  Training Method\n",
        "#@markdown The default is Dio\n",
        "F0_METHOD = \"dio\" #@param [\"crepe\", \"crepe-tiny\", \"parselmouth\", \"dio\", \"harvest\"]\n",
        "!svc pre-hubert -fm {F0_METHOD}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EZFaZlUQSnoI"
      },
      "outputs": [],
      "source": [
        "#@title Training\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir drive/MyDrive/so-vits-svc-fork/logs/44k\n",
        "!svc train --model-path drive/MyDrive/so-vits-svc-fork/logs/44k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AeEsZTZ4S4fj"
      },
      "outputs": [],
      "source": [
        "#@title Training Cluster Model\n",
        "!svc train-cluster --output-path drive/MyDrive/so-vits-svc-fork/logs/44k/kmeans.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_99k5PV_TSi9"
      },
      "source": [
        "# Inference\n",
        "This set is for using the SVC model for conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "vlnt26CKTWP9"
      },
      "outputs": [],
      "source": [
        "#@title **INFERENCE**\n",
        "#@markdown #INFERING USING PRE/TRAINED SVC MODEL\n",
        "#@markdown * remove **\".wav\"** on AUDIO\n",
        "from IPython.display import Audio\n",
        "\n",
        "AUDIO = \"\" #@param {type:\"string\"}\n",
        "MODEL = \"\" #@param {type:\"string\"}\n",
        "CONFIG = \"\" #@param {type:\"string\"}\n",
        "#@markdown * Change according to your model's voice pitch. 12 = 1 Octave | -12 = -1 Octave.\n",
        "#@markdown * Higher pitch audio to Lower pitch Model usually use -12 to -24; Vice Versa\n",
        "PITCH = -12 #@param {type:\"integer\"}\n",
        "#@markdown * Options, or leave it by default\n",
        "Auto_Predict = False #@param {type:\"boolean\"}\n",
        "Pitch_Bypass = False #@param {type:\"boolean\"}\n",
        "DisplayAudio_Infer = False #@param {type:\"boolean\"}\n",
        "\n",
        "def Auto_PredictFalse():\n",
        "  if Pitch_Bypass:\n",
        "    !svc infer {AUDIO}.wav -c {CONFIG} -m {MODEL} -na\n",
        "  else:\n",
        "    !svc infer {AUDIO}.wav -c {CONFIG} -m {MODEL} -na -t {PITCH}\n",
        "\n",
        "def Auto_PredictTrue():\n",
        "  if Pitch_Bypass:\n",
        "    !svc infer {AUDIO}.wav -c {CONFIG} -m {MODEL}\n",
        "  else:\n",
        "    !svc infer {AUDIO}.wav -c {CONFIG} -m {MODEL} -t {PITCH}\n",
        "\n",
        "if Auto_Predict:\n",
        "    Auto_PredictTrue()\n",
        "else:\n",
        "    Auto_PredictFalse()\n",
        "\n",
        "#@markdown Displaying audio can restart the runtime sometimes\n",
        "if DisplayAudio_Infer :\n",
        "  display(Audio(f\"{AUDIO}.out.wav\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Dan5obwKROnZ",
        "x4Zlj0fa-RNd",
        "lH_-DIk1RgTL",
        "BlMZYZIbRKdk",
        "_99k5PV_TSi9"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyNUVVq9EC2qD7JRUHlNfwAC",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}